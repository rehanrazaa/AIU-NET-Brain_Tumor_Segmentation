# -*- coding: utf-8 -*-
"""Finalized_New_AIU-NET_BTS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KANVaG1PJgJK1pdIeSaE2i0J0y3U_LB6

# **This is the Final notebook - AIU-Net for BTS**

## **Importing Libraries**
"""

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.utils import plot_model
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv3D, Conv3DTranspose, MaxPooling3D, BatchNormalization, Activation, Concatenate
from tensorflow.keras.models import Model

import numpy as np
import nibabel as nib
import glob
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
from tifffile import imsave
import random
import tensorflow.keras.backend as K

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
from tensorflow.keras import models, layers, regularizers
from keras.models import Model
from keras.layers import Input, Conv3D, MaxPooling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda
from tensorflow.keras.optimizers import Adam
from keras.metrics import MeanIoU
from tensorflow.keras.callbacks import ModelCheckpoint
import tensorflow.keras.backend as K
from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout,Maximum

from google.colab import drive
drive.mount('/content/drive')

"""## **Defining Loss Functions and Dice Coefficents**"""

def _dice_hard_coe(target, output, smooth=1e-5):
    output = tf.cast(output, dtype=tf.float32)
    target = tf.cast(target, dtype=tf.float32)

    inse = tf.reduce_sum(tf.multiply(output, target))
    l = tf.reduce_sum(output)
    r = tf.reduce_sum(target)
    hard_dice = (2. * inse + smooth) / (l + r + smooth)
    return tf.reduce_mean(hard_dice)

def brats_wt(y_true, y_pred):
    # whole tumor
    y_true = tf.argmax(y_true, axis=-1)
    y_pred = tf.argmax(y_pred, axis=-1)
    gt_wt = tf.cast(tf.identity(y_true), tf.int32)
    gt_wt = tf.where(tf.equal(2, gt_wt), 1 * tf.ones_like(gt_wt), gt_wt)  # ground_truth_wt[ground_truth_wt == 2] = 1
    gt_wt = tf.where(tf.equal(3, gt_wt), 1 * tf.ones_like(gt_wt), gt_wt)  # ground_truth_wt[ground_truth_wt == 3] = 1
    pd_wt = tf.cast(tf.round(tf.identity(y_pred)), tf.int32)
    pd_wt = tf.where(tf.equal(2, pd_wt), 1 * tf.ones_like(pd_wt), pd_wt)  # predictions_wt[predictions_wt == 2] = 1
    pd_wt = tf.where(tf.equal(3, pd_wt), 1 * tf.ones_like(pd_wt), pd_wt)  # predictions_wt[predictions_wt == 3] = 1
    return _dice_hard_coe(gt_wt, pd_wt)


def brats_tc(y_true, y_pred):
    # tumor core
    y_true = tf.argmax(y_true, axis=-1)
    y_pred = tf.argmax(y_pred, axis=-1)
    gt_tc = tf.cast(tf.identity(y_true), tf.int32)
    gt_tc = tf.where(tf.equal(2, gt_tc), 0 * tf.ones_like(gt_tc), gt_tc)  # ground_truth_tc[ground_truth_tc == 2] = 0
    gt_tc = tf.where(tf.equal(3, gt_tc), 1 * tf.ones_like(gt_tc), gt_tc)  # ground_truth_tc[ground_truth_tc == 3] = 1
    pd_tc = tf.cast(tf.round(tf.identity(y_pred)), tf.int32)
    pd_tc = tf.where(tf.equal(2, pd_tc), 0 * tf.ones_like(pd_tc), pd_tc)  # predictions_tc[predictions_tc == 2] = 0
    pd_tc = tf.where(tf.equal(3, pd_tc), 1 * tf.ones_like(pd_tc), pd_tc)  # predictions_tc[predictions_tc == 3] = 1
    return _dice_hard_coe(gt_tc, pd_tc)


def brats_et(y_true, y_pred):
    # enhancing tumor
    y_true = tf.argmax(y_true, axis=-1)
    y_pred = tf.argmax(y_pred, axis=-1)
    gt_et = tf.cast(tf.identity(y_true), tf.int32)
    gt_et = tf.where(tf.equal(1, gt_et), 0 * tf.ones_like(gt_et), gt_et)  # ground_truth_et[ground_truth_et == 1] = 0
    gt_et = tf.where(tf.equal(2, gt_et), 0 * tf.ones_like(gt_et), gt_et)  # ground_truth_et[ground_truth_et == 2] = 0
    gt_et = tf.where(tf.equal(3, gt_et), 1 * tf.ones_like(gt_et), gt_et)  # ground_truth_et[ground_truth_et == 3] = 1
    pd_et = tf.cast(tf.round(tf.identity(y_pred)), tf.int32)
    pd_et = tf.where(tf.equal(1, pd_et), 0 * tf.ones_like(pd_et), pd_et)  # predictions_et[predictions_et == 1] = 0
    pd_et = tf.where(tf.equal(2, pd_et), 0 * tf.ones_like(pd_et), pd_et)  # predictions_et[predictions_et == 2] = 0
    pd_et = tf.where(tf.equal(3, pd_et), 1 * tf.ones_like(pd_et), pd_et)  # predictions_et[predictions_et == 3] = 1
    return _dice_hard_coe(gt_et, pd_et)

def dice_coefficient(y_true, y_pred, epsilon=0.00001):
    """
    Dice = (2*|X & Y|)/ (|X|+ |Y|)
         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))
    ref: https://arxiv.org/pdf/1606.04797v1.pdf

    """
    axis = (0,1,2,3)
    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon
    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon
    return K.mean((dice_numerator)/(dice_denominator))

def soft_dice_loss(y_true, y_pred, axis=(1, 2, 3),
                   epsilon=0.00001):
    """
    Compute mean soft dice loss over all abnormality classes.

    Args:
        y_true (Tensorflow tensor): tensor of ground truth values for all classes.
                                    shape: (num_classes, x_dim, y_dim, z_dim)
        y_pred (Tensorflow tensor): tensor of soft predictions for all classes.
                                    shape: (num_classes, x_dim, y_dim, z_dim)
        axis (tuple): spatial axes to sum over when computing numerator and
                      denominator in formula for dice loss.
                      Hint: pass this as the 'axis' argument to the K.sum
                            and K.mean functions.
        epsilon (float): small constant added to numerator and denominator to
                        avoid divide by 0 errors.
    Returns:
        dice_loss (float): computed value of dice loss.
    """

    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon
    dice_denominator = K.sum(y_true**2, axis=axis) + K.sum(y_pred**2, axis=axis) + epsilon
    dice_loss = 1 - K.mean((dice_numerator)/(dice_denominator))

    return dice_loss

# Computing Sensitivity
def sensitivity(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    return true_positives / (possible_positives + K.epsilon())


# Computing Specificity
def specificity(y_true, y_pred):
    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))
    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))
    return true_negatives / (possible_negatives + K.epsilon())

def sensitivity_wt(true_positive, false_negative):
    """
    Calculate sensitivity (true positive rate) given the true positive and false negative counts.
    """
    return true_positive / (true_positive + false_negative)


def specificity_wt(true_negative, false_positive):
    """
    Calculate specificity (true negative rate) given the true negative and false positive counts.
    """
    return true_negative / (true_negative + false_positive)

def sensitivity_tc(true_positive, false_negative):
    """
    Calculate sensitivity (true positive rate) given the true positive and false negative counts.
    """
    return true_positive / (true_positive + false_negative)


def specificity_tc(true_negative, false_positive):
    """
    Calculate specificity (true negative rate) given the true negative and false positive counts.
    """
    return true_negative / (true_negative + false_positive)

def sensitivity_et(true_positive, false_negative):
    """
    Calculate sensitivity (true positive rate) given the true positive and false negative counts.
    """
    return true_positive / (true_positive + false_negative)


def specificity_et(true_negative, false_positive):
    """
    Calculate specificity (true negative rate) given the true negative and false positive counts.
    """
    return true_negative / (true_negative + false_positive)

"""## **Defining the Custom Data Image Loader**"""

import os
import numpy as np


def load_img(img_dir, img_list):
    images=[]
    for i, image_name in enumerate(img_list):
        if (image_name.split('.')[1] == 'npy'):

            image = np.load(img_dir+image_name)

            images.append(image)
    images = np.array(images)

    return(images)

def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):

    L = len(img_list)

    #keras needs the generator infinite, so we will use while true
    while True:

        batch_start = 0
        batch_end = batch_size

        while batch_start < L:
            limit = min(batch_end, L)

            X = load_img(img_dir, img_list[batch_start:limit])
            Y = load_img(mask_dir, mask_list[batch_start:limit])

            yield (X,Y) #a tuple with two numpy arrays with batch_size samples

            batch_start += batch_size
            batch_end += batch_size

#Test the generator

train_img_dir = "/content/drive/MyDrive/BrainTumor/Data_ImageGen128/Train_128_npy/train_images_128/"
train_mask_dir = "/content/drive/MyDrive/BrainTumor/Data_ImageGen128/Train_128_npy/train_masks_128/"
train_img_list=os.listdir(train_img_dir)
train_mask_list = os.listdir(train_mask_dir)

batch_size = 2
#Verify generator.... In python 3 next() is renamed as __next__()
img, msk = train_img_datagen.__next__()

img_num = random.randint(0,img.shape[0]-1)
test_img=img[img_num]
test_mask=msk[img_num]
test_mask=np.argmax(test_mask, axis=3)

n_slice=random.randint(0, test_mask.shape[2])
plt.figure(figsize=(12, 8))

plt.subplot(221)
plt.imshow(test_img[:,:,n_slice, 0], cmap='gray')
plt.title('Image flair')

plt.subplot(222)
plt.imshow(test_img[:,:,n_slice, 1], cmap='gray')
plt.title('Image t1ce')

plt.subplot(223)
plt.imshow(test_img[:,:,n_slice, 2], cmap='gray')
plt.title('Image t2')

plt.subplot(224)
plt.imshow(test_mask[:,:,n_slice])
plt.title('Mask')
plt.show()

#Define the image generators for training and validation

train_img_dir = "/content/drive/MyDrive/BrainTumor/Data_ImageGen128/Train_128_npy/train_images_128/"
train_mask_dir = "/content/drive/MyDrive/BrainTumor/Data_ImageGen128/Train_128_npy/train_masks_128/"

val_img_dir = "/content/drive/MyDrive/BrainTumor/Data_ImageGen128/Valid_128_npy/valid_images_128/"
val_mask_dir = "/content/drive/MyDrive/BrainTumor/Data_ImageGen128/Valid_128_npy/valid_masks_128/"

train_img_list=os.listdir(train_img_dir)
train_mask_list = os.listdir(train_mask_dir)

val_img_list=os.listdir(val_img_dir)
val_mask_list = os.listdir(val_mask_dir)

"""## **Loading data using Custom Data Generator**"""

batch_size = 4

train_img_datagen = imageLoader(train_img_dir, train_img_list,
                                train_mask_dir, train_mask_list, batch_size)

val_img_datagen = imageLoader(val_img_dir, val_img_list,
                                val_mask_dir, val_mask_list, batch_size)

#Verify generator.... In python 3 next() is renamed as __next__()
img, msk = train_img_datagen.__next__()

"""# **Final AIU-Net Architecture With 5 Levels**"""

def conv_block(input_mat):
  num_filters = 32
  kernel_size = 3
  batch_norm = True

  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(input_mat)
  X = BatchNormalization()(X)
  X = Activation('leaky_relu')(X)

  X = Conv3D(num_filters,kernel_size=(kernel_size,kernel_size,kernel_size),strides=(1,1,1),padding='same')(X)
  X = BatchNormalization()(X)
  X = Activation('leaky_relu')(X)

  return X

def inception_block(inputs):
    n_filters = 32
    conv1x1 = Conv3D(n_filters, kernel_size=1, activation='relu', padding='same')(inputs)

    conv3x3 = Conv3D(n_filters, kernel_size=1, activation='relu', padding='same')(inputs)
    conv3x3 = Conv3D(n_filters, kernel_size=3, activation='relu', padding='same')(conv3x3)

    conv5x5 = Conv3D(n_filters, kernel_size=1, activation='relu', padding='same')(inputs)
    conv5x5 = Conv3D(n_filters, kernel_size=5, activation='relu', padding='same')(conv5x5)

    maxpool3x3 = MaxPooling3D(pool_size=(3, 3, 3), strides=1, padding='same')(inputs)
    maxpool3x3 = Conv3D(n_filters, kernel_size=1, activation='relu', padding='same')(maxpool3x3)

    output = concatenate([conv1x1, conv3x3, conv5x5, maxpool3x3], axis=-1)
    return output

def attention_block(inputs):
    f = Conv3D(1, kernel_size=1, activation='relu', padding='same')(inputs)
    g = Conv3D(1, kernel_size=1, activation='relu', padding='same')(inputs)
    h = Conv3D(inputs.shape[-1], kernel_size=1, activation='relu', padding='same')(inputs)
    s = tf.keras.layers.multiply([f, g])
    s = tf.keras.layers.Reshape((-1,))(s)
    s = tf.keras.layers.Activation('softmax')(s)
    s = tf.keras.layers.Reshape(inputs.shape[1:-1] + (1,))(s)
    output = tf.keras.layers.multiply([h, s])
    return output

# Define 3D Attention Inception U-Net model with attention blocks only at the encoder part
def attention_inception_unet(input_shape):
    # Input Layer
    inputs = Input(shape=input_shape)

    # Level 1 (Encoder)
    enc_attention1 = attention_block(inputs)
    enc_inception1 = inception_block(enc_attention1)
    enc_pool1 = MaxPooling3D(pool_size=(2, 2, 2))(enc_inception1)

    # Level 2
    enc_attention2 = attention_block(enc_pool1)
    enc_inception2 = inception_block(enc_attention2)
    enc_pool2 = MaxPooling3D(pool_size=(2, 2, 2))(enc_inception2)

    # Level 3
    enc_attention3 = attention_block(enc_pool2)
    enc_inception3 = inception_block(enc_attention3)
    enc_pool3 = MaxPooling3D(pool_size=(2, 2, 2))(enc_inception3)

    # Level 4
    enc_attention4 = attention_block(enc_pool3)
    enc_inception4 = inception_block(enc_attention4)
    enc_pool4 = MaxPooling3D(pool_size=(2, 2, 2))(enc_inception4)

    # Level 5 (Bridge)
    bridge_conv = Conv3D(filters=1024, kernel_size=(3, 3, 3), padding='same', activation='relu')(enc_pool4)
    bridge_inception = inception_block(bridge_conv)

    # Level 4 (Decoder)

    dec_upconv4 = Conv3DTranspose(filters=512, kernel_size=(2, 2, 2), strides=(2, 2, 2), padding='same')(bridge_inception)
    dec_concat4 = Concatenate(axis=-1)([dec_upconv4, enc_inception4])
    dec_inception4 = conv_block(dec_concat4)
    #print("level 4 DEc",dec_inception4.shape)

    # Level 3
    dec_upconv3 = Conv3DTranspose(filters=256, kernel_size=(2, 2, 2), strides=(2, 2, 2), padding='same')(dec_inception4)
    dec_concat3 = Concatenate(axis=-1)([dec_upconv3, enc_inception3])
    dec_inception3 = conv_block(dec_concat3)

    # Level 2
    dec_upconv2 = Conv3DTranspose(filters=128, kernel_size=(2, 2, 2), strides=(2, 2, 2), padding='same')(dec_inception3)
    dec_concat2 = Concatenate(axis=-1)([dec_upconv2, enc_inception2])
    dec_inception2 = conv_block(dec_concat2)

    # Level 1
    dec_upconv1 = Conv3DTranspose(filters=64, kernel_size=(2, 2, 2), strides=(2, 2, 2), padding='same')(dec_inception2)
    dec_concat1 = Concatenate(axis=-1)([dec_upconv1, enc_inception1])
    dec_inception1 = conv_block(dec_concat1)

    # Output
    output = Conv3D(filters=4, kernel_size=(1, 1, 1), activation='softmax')(dec_inception1)

    model = Model(inputs=inputs, outputs=output)
    return model

input_shape = (128, 128, 128, 4) # Adjust the input shape according to data
model = attention_inception_unet(input_shape)

print(model.input)

print(model.output)

model.summary()

"""## **Compiling the Model**"""

import tensorflow as tf
metrics = [dice_coefficient, brats_wt , brats_tc ,brats_et,sensitivity,specificity]
learning_rate = 0.0005
optimizer = tf.keras.optimizers.Adam(learning_rate)

model.compile(optimizer = optimizer, loss=soft_dice_loss, metrics=metrics)

#Fit the model
steps_per_epoch = len(train_img_list)//batch_size
val_steps_per_epoch = len(val_img_list)//batch_size

# Define checkpoint callback to save best model to Google Drive
checkpoint_path = '/content/drive/MyDrive/Final_MODEL/Final_Model_Results'
callbacks = []
callbacks.append(ModelCheckpoint(checkpoint_path + '/IAUnet_epoch-{epoch}.h5'))

"""## **Training of the Proposed Model**"""

history=model.fit(train_img_datagen,
          steps_per_epoch=steps_per_epoch,
          epochs=100,
          validation_data=val_img_datagen,
          validation_steps=val_steps_per_epoch,
          verbose=1
          )

"""## **In case start training from last saved Model**"""

initial_epochs = 100

initial_epoch_number  = 8
res_unet_M = keras.models.load_model("/content/drive/MyDrive/Final_MODEL/Final_Model_Results/IAUnet_epoch-8.h5",
                                 custom_objects={'soft_dice_loss': soft_dice_loss,
                                 'dice_coefficient':dice_coefficient,'brats_wt':brats_wt,
                                 'brats_tc' : brats_tc , 'brats_et':brats_et, 'sensitivity':sensitivity,'specificity':specificity
                                 },)

history=res_unet_M.fit(train_img_datagen,
          steps_per_epoch=steps_per_epoch,
          epochs=initial_epochs,
          initial_epoch=initial_epoch_number,
          validation_data=val_img_datagen,
          validation_steps=val_steps_per_epoch,
          callbacks=[callbacks], verbose=1
          )



