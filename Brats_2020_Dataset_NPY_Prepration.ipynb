{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **This notebook is about how to read 3D .nii Files of the BraTS dataset and convert it into 3D npy file for efficient training of the model**"
      ],
      "metadata": {
        "id": "cMJ05Pf78UTC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOEa7ovyMuWu"
      },
      "outputs": [],
      "source": [
        "# Importing necesaary Libraries\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import glob\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from tifffile import imsave\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cl5kiWK5M0C8"
      },
      "outputs": [],
      "source": [
        "#Here the path where the dataset is stored\n",
        "TRAIN_DATASET_PATH = '/content/drive/MyDrive/Brats-2020-Dataset/Brats2020_Training_dataset/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7ho28TlNX2X"
      },
      "outputs": [],
      "source": [
        "# BraTS 2020 dataset contain 4 diffierent modalities and 1 segmentation mask\n",
        "# Here we set the path of each modality\n",
        "t1_list = sorted(glob.glob('path'))\n",
        "t2_list = sorted(glob.glob('path'))\n",
        "t1ce_list = sorted(glob.glob('path'))\n",
        "flair_list = sorted(glob.glob('path'))\n",
        "mask_list = sorted(glob.glob('path'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tUDVaqAKN3JU"
      },
      "outputs": [],
      "source": [
        "for img in range(len(t2_list)):   #Using t1_list as all lists are of same size\n",
        "    print(\"Now preparing image and masks number: \", img)\n",
        "\n",
        "    temp_image_t1=nib.load(t1_list[img]).get_fdata()\n",
        "    temp_image_t1=scaler.fit_transform(temp_image_t1.reshape(-1, temp_image_t1.shape[-1])).reshape(temp_image_t1.shape)\n",
        "\n",
        "    temp_image_t2=nib.load(t2_list[img]).get_fdata()\n",
        "    temp_image_t2=scaler.fit_transform(temp_image_t2.reshape(-1, temp_image_t2.shape[-1])).reshape(temp_image_t2.shape)\n",
        "\n",
        "    temp_image_t1ce=nib.load(t1ce_list[img]).get_fdata()\n",
        "    temp_image_t1ce=scaler.fit_transform(temp_image_t1ce.reshape(-1, temp_image_t1ce.shape[-1])).reshape(temp_image_t1ce.shape)\n",
        "\n",
        "    temp_image_flair=nib.load(flair_list[img]).get_fdata()\n",
        "    temp_image_flair=scaler.fit_transform(temp_image_flair.reshape(-1, temp_image_flair.shape[-1])).reshape(temp_image_flair.shape)\n",
        "\n",
        "    temp_mask=nib.load(mask_list[img]).get_fdata()\n",
        "    temp_mask=temp_mask.astype(np.uint8)\n",
        "    temp_mask[temp_mask==4] = 3  #Reassign mask values 4 to 3\n",
        "    print(np.unique(temp_mask))\n",
        "\n",
        "\n",
        "    temp_combined_images = np.stack([temp_image_flair, temp_image_t1ce, temp_image_t2, temp_image_t1], axis=3)\n",
        "\n",
        "    #Crop to a size to be divisible by 64 so we can later extract 64x64x64 patches.\n",
        "    # Also it will resize our dataset from 240x240x155 to 128x128x128 so that  we can efficiently manage the resouces\n",
        "    #cropping x, y, and z\n",
        "    # In resize we make sure that there will be no information lost\n",
        "    temp_combined_images=temp_combined_images[56:184, 56:184, 13:141]\n",
        "    temp_mask = temp_mask[56:184, 56:184, 13:141]\n",
        "\n",
        "    val, counts = np.unique(temp_mask, return_counts=True)\n",
        "\n",
        "    if (1 - (counts[0]/counts.sum())) > 0.01:  #At least 1% useful volume with labels that are not 0\n",
        "        print(\"Saving the stacking npy file\")\n",
        "        temp_mask= to_categorical(temp_mask, num_classes=4)\n",
        "        np.save('/content/drive/MyDrive/Brats-2020-Dataset/BraTS2021_NPY_Files/train_images/image_'+str(img)+'.npy', temp_combined_images)\n",
        "        np.save('/content/drive/MyDrive/Brats-2020-Dataset/BraTS2021_NPY_Files/train_masks/mask_'+str(img)+'.npy', temp_mask)\n",
        "\n",
        "    else:\n",
        "        print(\"Not for any use.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}